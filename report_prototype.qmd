---
title: "EMMA Report Prototype"
description: Modeling vegetation postfire recovery data
author:
  - name: Adam Wilson & Glenn Moncrieff & Brian Maitner
editor_options: 
  chunk_output_type: console
output:
    html_document:
      toc: true
      toc_depth: 2
---

Page last updated at `r lubridate::now()`.


```{r, echo=F, message = F, results = "hide"}
library(targets)
library(tidyverse)
library(doParallel)
library(raster)
library(lubridate)
library(sf)
#library(rnoaa)
library(xts)
library(plotly)
library(leaflet)
library(dygraphs)

```


# Park-specific Information

## NDVI and Time Since Fire

```{r data_prep, echo = FALSE, warning = FALSE, message = FALSE,include=FALSE}

# CREATE wgs84 version of the park polygon

    focal_park %>% 
    st_transform(crs = st_crs(4326)) -> focal_wgs

# Create buffered fire age polygon

    # make park-specific fire ages file
      

      fires_wgs %>%
      st_crop(y = focal_wgs %>%
                st_buffer(dist = 10000)) ->
        focal_fires
      
      
      park_no_spaces <- gsub(pattern = " ",replacement = "_",x = park_name)

      focal_fires %>%
        st_write(dsn = file.path(temp_directory, paste(park_no_spaces,"fires.gpkg",sep = "_")),
                 append=FALSE,
                 quiet = TRUE
                 )

      robust_pb_upload(file = file.path(temp_directory, paste(park_no_spaces,"fires.gpkg",sep = "_")),
                       repo = "AdamWilsonLab/emma_report",
                       tag = park_data_tag)
      
      file.remove(file.path(temp_directory, paste(park_no_spaces,"fires.gpkg",sep = "_")))
      

# Park-specific file link
    park_fires_file  <- paste("https://github.com/AdamWilsonLab/emma_report/releases/download/park_data/",
                              paste(park_no_spaces,"fires.gpkg",sep= "_"),sep = "")

# Create a truncated version of the fire maps (ranging from 1-20)

  fires_wgs %>%
    mutate(Years = case_when(Years > 20 ~ 20,
                             Years <=20 ~ Years)) -> fires_wgs_truncated
  


#Note that the "addLegend_decreasing" isn't quite right, but might be close enough if you feel strongly about the ordering

addLegend_decreasing <- function (map, position = c("topright", "bottomright", "bottomleft", 
			    "topleft"), pal, values, na.label = "NA", bins = 7, colors, 
		  opacity = 0.5, labels = NULL, labFormat = labelFormat(), 
		  title = NULL, className = "info legend", layerId = NULL, 
		  group = NULL, data = getMapData(map), decreasing = FALSE) {
	position <- match.arg(position)
	type <- "unknown"
	na.color <- NULL
	extra <- NULL
	if (!missing(pal)) {
		if (!missing(colors)) 
			stop("You must provide either 'pal' or 'colors' (not both)")
		if (missing(title) && inherits(values, "formula")) 
			title <- deparse(values[[2]])
		values <- evalFormula(values, data)
		type <- attr(pal, "colorType", exact = TRUE)
		args <- attr(pal, "colorArgs", exact = TRUE)
		na.color <- args$na.color
		if (!is.null(na.color) && col2rgb(na.color, alpha = TRUE)[[4]] == 
		    0) {
			na.color <- NULL
		}
		if (type != "numeric" && !missing(bins)) 
			warning("'bins' is ignored because the palette type is not numeric")
		if (type == "numeric") {
			cuts <- if (length(bins) == 1) 
				pretty(values, bins)
			else bins	
			
			if (length(bins) > 2) 
				if (!all(abs(diff(bins, differences = 2)) <= 
				         sqrt(.Machine$double.eps))) 
					stop("The vector of breaks 'bins' must be equally spaced")
			n <- length(cuts)
			r <- range(values, na.rm = TRUE)
			cuts <- cuts[cuts >= r[1] & cuts <= r[2]]
			n <- length(cuts)
			p <- (cuts - r[1])/(r[2] - r[1])
			extra <- list(p_1 = p[1], p_n = p[n])
			p <- c("", paste0(100 * p, "%"), "")
			if (decreasing == TRUE){
				colors <- pal(rev(c(r[1], cuts, r[2])))
				labels <- rev(labFormat(type = "numeric", cuts))
			}else{
				colors <- pal(c(r[1], cuts, r[2]))
				labels <- rev(labFormat(type = "numeric", cuts))
			}
			colors <- paste(colors, p, sep = " ", collapse = ", ")
			
		}
		else if (type == "bin") {
			cuts <- args$bins
			n <- length(cuts)
			mids <- (cuts[-1] + cuts[-n])/2
			if (decreasing == TRUE){
				colors <- pal(rev(mids))
				labels <- rev(labFormat(type = "bin", cuts))
			}else{
				colors <- pal(mids)
				labels <- labFormat(type = "bin", cuts)
			}
			
		}
		else if (type == "quantile") {
			p <- args$probs
			n <- length(p)
			cuts <- quantile(values, probs = p, na.rm = TRUE)
			mids <- quantile(values, probs = (p[-1] + p[-n])/2, 
				 na.rm = TRUE)
			if (decreasing == TRUE){
				colors <- pal(rev(mids))
				labels <- rev(labFormat(type = "quantile", cuts, p))
			}else{
				colors <- pal(mids)
				labels <- labFormat(type = "quantile", cuts, p)
			}
		}
		else if (type == "factor") {
			v <- sort(unique(na.omit(values)))
			colors <- pal(v)
			labels <- labFormat(type = "factor", v)
			if (decreasing == TRUE){
				colors <- pal(rev(v))
				labels <- rev(labFormat(type = "factor", v))
			}else{
				colors <- pal(v)
				labels <- labFormat(type = "factor", v)
			}
		}
		else stop("Palette function not supported")
		if (!any(is.na(values))) 
			na.color <- NULL
	}
	else {
		if (length(colors) != length(labels)) 
			stop("'colors' and 'labels' must be of the same length")
	}
	legend <- list(colors = I(unname(colors)), labels = I(unname(labels)), 
	               na_color = na.color, na_label = na.label, opacity = opacity, 
	               position = position, type = type, title = title, extra = extra, 
	               layerId = layerId, className = className, group = group)
	invokeMethod(map, data, "addLegend", legend)
}


# Create continuous palettes

  pal <- colorNumeric(palette = "Reds",
                      domain = fires_wgs_truncated$Years,
                      reverse = TRUE)

  antipal <- colorNumeric(palette = "Reds",
                          domain = fires_wgs_truncated$Years,reverse = FALSE)
  
  
  ndvi_pal <- colorNumeric(palette = c( "#FFFFCC", "#41B6C4","#0C2C84"),
                           #domain =  values(most_recent_ndvi_raster),
                           domain =  c(-1,0,1),
                           na.color = "transparent")

  ndwi_pal <- colorNumeric(palette = c( "#FFFFCC", "#41B6C4","#0C2C84"),
                           #domain =  values(terra::rast(ndwi_rast)),
                           domain = c(-1,1),
                           na.color = "transparent")
  
  ndwi_bin_pal <- colorBin(palette = c( "#FFFFCC", "#41B6C4","#0C2C84"),
                           #domain =  values(terra::rast(ndwi_rast)),
                           domain = c(-1,1),
                           bins = c(-1,-.3,0.0,0.2,1),
                           na.color = "transparent",
                           alpha = TRUE)


# Create bounding box for plotting  
  
bbox <- st_bbox(focal_wgs) %>%
  as.vector()



```


```{r prep_weather_data, echo = FALSE, warning = FALSE, message = FALSE}

# Process the station and weather data

  # Get data for closest weather stations
  
    cent <- suppressWarnings( focal_park %>%
                                st_union()%>%
                                st_centroid())
    

    closest_stations <- 
      data.frame(station = stations_sf$STNID,
                 name = stations_sf$NAME,
               distance = as.numeric(st_distance(cent,stations_sf)))
    
    closest_stations <- closest_stations[order(closest_stations$distance),]
    
    closest_stations <- closest_stations$station[1:n_stations]
    
    closest_stations %>%
          gsub(pattern = "/",replacement = "",fixed = TRUE)%>% #what kind of sadist puts a slash in a name?
          gsub(pattern = " ",replacement = "_") %>%
          gsub(pattern = ")",replacement = "_",fixed = TRUE) %>%
          gsub(pattern = "(",replacement = "_",fixed = TRUE) %>%
          paste(.,".gz.parquet",sep = "")-> closest_stations
    

    robust_pb_download(file = closest_stations,
                dest = temp_directory,
                repo = "AdamWilsonLab/emma_report",
                tag = "GSOD",
                max_attempts = max_attempts,
                sleep_time = sleep_time,
                show_progress=FALSE) -> to_rm
    
    if(exists("to_rm")){rm(to_rm)}
    
  
  #Hack in case some of the files aren't downloaded correctly.  
    closest_stations  <- intersect(closest_stations,
                                   list.files(temp_directory))
  
  focal_weather  <- open_dataset(file.path(temp_directory, closest_stations))
  
  focal_weather %>% collect() -> focal_weather
  
  
  #fix station names in focal weather (missing in many case)
  
    # stations %>%
    # dplyr::select(usaf,wban,station_name)%>%
    # inner_join(y = focal_weather,
    #            by = c("usaf"="usaf_station","wban"="wban_station"),
    #            multiple = "all")%>%
    # dplyr::rename(station_name = station_name.x)-> focal_weather

  #with dygraphs, first element should be x axis, or else do it as an xts
  
  # probably easiest to do xts, since its a time series anyway
  
  # focal_weather %>%
  #   as.data.frame() %>% #for some reason, this code throws an error without this line.  no idea why.
  #   mutate(year = substr(x = date,1,4),
  #          month = substr(x = date,5,6),
  #          day = substr(x=date,7,8),
  #          hour= substr(x=time,1,2),
  #          minute = substr(x=time,3,4)) %>%
  #   mutate(date_time = paste(year,month,day,hour,minute,sep = "-"))%>%
  #   mutate(date_time = strptime(date_time,format = "%Y-%m-%d-%H-%M"))%>%
  #   dplyr::filter(!is.na(date_time)) -> focal_weather
  
  
  #reformatting the GSOD to match NOAA format
  focal_weather %>%
    as.data.frame() %>% #for some reason, this code throws an error without this line.  no idea why.
    mutate(year =YEAR,
           month = MONTH,
           day = DAY,
           station_name = NAME,
           mean_precip_mm = PRCP,
           temp_c = TEMP)%>%
    mutate(date_time = paste(year,month,day,sep = "-"))%>%
    mutate(date_time = strptime(date_time,format = "%Y-%m-%d"))%>%
    dplyr::filter(!is.na(date_time)) -> focal_weather
  
  
  
  #Filter out oldest data
  
  focal_weather <- 
    focal_weather%>%
      filter(date_time > as_datetime(min_date,tz =tz(focal_weather$date_time)))
  
  #Generate precip dataset
  
focal_weather %>%
  group_by(station_name,year,month)%>%
  summarise(monthly_precip_mm = sum(na.omit(mean_precip_mm)))%>%
  ungroup() %>%
  mutate(date_time = paste(year,month,01,sep = "-"))%>%
  mutate(date_time = strptime(date_time,format = "%Y-%m-%d"))%>%
  mutate(date_time = lubridate::floor_date(date_time)-1)%>%
  dplyr::filter(!is.na(date_time))%>%
  dplyr::select(date_time,station_name, monthly_precip_mm) %>%
  pivot_wider(values_from = monthly_precip_mm,
              names_from = station_name,
              values_fn = mean) %>%
    mutate(doy =  lubridate::yday(date_time) ) %>%
    left_join(x=.,
              y  = group_by(., doy) %>%
                summarize(mean = mean(c_across(!contains(c("doy","date_time"))),
                                          na.rm=TRUE))
              ) %>%
  dplyr::select(-doy)%>%
  xts::xts(order.by = .$date_time) -> focal_precip


  
  # focal_weather %>%
  #   dplyr::select(date_time, usaf_station, mean_precip_mm) %>%
  # pivot_wider(values_from = mean_precip_mm,
  #               names_from = usaf_station,
  #             values_fn = mean) %>%
  #   xts::xts(order.by = .$date_time) -> focal_precip
  
  # Generate temp dataset
  
  # focal_weather%>%
  #   dplyr::select(date_time, station_name, temp_c) %>%
  #   pivot_wider(values_from = temp_c,
  #               names_from = station_name,
  #               values_fn = mean) %>%
  #   xts::xts(order.by = .$date_time) -> focal_temp
  
    
    #mean daily temp dataset

    focal_weather%>%
  group_by(station_name,year,month,day)%>%
  summarise(daily_temp_C = mean(na.omit(temp_c)))%>%
  ungroup() %>%
mutate(date_time = paste(year,month,day,sep = "-"))%>%
  mutate(date_time = strptime(date_time,format = "%Y-%m-%d"))%>%
  dplyr::filter(!is.na(date_time))%>%
  dplyr::select(date_time,station_name, daily_temp_C) %>%
  pivot_wider(values_from = daily_temp_C,
              names_from = station_name,
              values_fn = mean) %>%
    mutate(doy =  lubridate::yday(date_time) ) %>%
    left_join(x=.,
              y  = group_by(., doy) %>%
                summarize(mean = mean(c_across(!contains(c("doy","date_time"))),
                                          na.rm=TRUE))
              ) %>%
  dplyr::select(-doy)%>%
    xts::xts(order.by = .$date_time) -> focal_mean_daily_temp


  
  
#Generate sf of station points
  
  # focal_stations_sf <-
  # stations_sf %>%
  #   filter(usaf %in%gsub(pattern = ".gz.parquet",
  #                        replacement = "",x = closest_stations)) %>%
  #   st_transform(st_crs(fires_wgs_truncated))

  focal_stations_sf <-
  stations_sf %>%
    filter(STNID %in% gsub(pattern = ".gz.parquet",
                          replacement = "",
                          x = closest_stations)) %>%
    st_transform(st_crs(fires_wgs_truncated))
    
```

```{r ndvi_and_burns, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE}

  leaflet(data = focal_wgs) %>%
  addProviderTiles("Esri.NatGeoWorldMap", group = "NatGeo") %>%
    #addProviderTiles("NASAGIBS.ModisTerraTrueColorCR", group = "True Colors") %>%
    addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") %>%
  addPolygons(color = "black",
              stroke = TRUE,
              fill = FALSE,
              group = "Park") %>%
  addRasterImage(x = raster::raster(most_recent_ndvi_raster),
                 group = "NDVI",
                 colors = ndvi_pal)%>%
  addPolygons(data = fires_wgs_truncated,
              color = "red",
              fill = TRUE,
              fillOpacity = 0,
              stroke = TRUE,
              label = paste(fires_wgs$Years, "years since burn"),
              weight = 1,
              group = "Fire Outlines") %>%
    addPolygons(data = fires_wgs_truncated,
              color = ~antipal(Years),
              fillOpacity = .75,
              stroke = FALSE,
              label = fires_wgs$Years,
              group = "Fires") %>%
    addMarkers(data = focal_stations_sf,
               label = focal_stations_sf$station_name,
               group = "Stations") %>%
    hideGroup("Stations") %>%
    addLegend_decreasing(position = "bottomright",
            pal = pal,
            values = ~fires_wgs_truncated$Years,
    title = "Years<br/>Since<br/>Fire",
    opacity = 1) %>%
  leaflet::addLegend(position = "bottomright",
            pal = ndvi_pal,          
            values = ~values(raster::raster(most_recent_ndvi_raster)),
            #values = ~c(-1,1),
            opacity = 1,
            title = "NDVI") %>%
    addLayersControl(
    baseGroups = c("NatGeo","World Imagery"),
    overlayGroups = c("NDVI", "Fire Outlines","Fires", "Park", "Stations"),
    options = layersControlOptions(collapsed = FALSE),position = "topright") %>%
  fitBounds(bbox[1], bbox[2], bbox[3], bbox[4])

```

Figure 1. Leaflet map showing NDVI and the number of years since the most recent fire.  NA values in the NDVI layer indicate missing data (e.g. due to clouds, water, etc.).  NDVI data is is from `r most_recent_ndvi_date`. NA values in the fire layer indicate that no fires have been recorded for that area. Note that the color scale for fires has been truncated, and any sites with more than 20 years since fire appear as 20.  The number of years since fire can be seen by hovering your cursor over the polygon of interest. Fire data for the park are available at: `r park_fires_file`.


## Weather Data

```{r weatherdyplot, echo=FALSE, message=FALSE, warning=FALSE}

  # see: https://rstudio.github.io/dygraphs/


    library(dygraphs)
  
  

  dygraph(data = focal_precip[,colnames(focal_precip)[which(colnames(focal_precip)!="date_time")]],
          main = "Precipitation",
          xlab = "Date",
          ylab = "Precip. (mm)") %>%
    dySeries()%>%
    dyRangeSelector(dateWindow = c( Sys.Date() - time_window_days, Sys.Date())) -> precip_graph
  
# 
#   dygraph(data = focal_temp[,colnames(focal_temp)[which(colnames(focal_precip)!="date_time")]],
#           main = "Temperature",
#           xlab = "Date",
#           ylab = "Temp. (C)") %>%
#     dySeries()%>%
#     dyRangeSelector(dateWindow = c( Sys.Date() - time_window_days, Sys.Date())) -> temp_graph
# 

      dygraph(data = focal_mean_daily_temp[,colnames(focal_mean_daily_temp)[which(colnames(focal_mean_daily_temp)!="date_time")]],
          main = "Temperature",
          xlab = "Date",
          ylab = "Temp. (C)") %>%
    dySeries() %>%
    dyRangeSelector(dateWindow = c( Sys.Date() - time_window_days, Sys.Date())) -> mean_temp_graph

  #mean temp dataset
#     focal_weather%>%
#   group_by(station_name,year,month)%>%
#   summarise(monthly_temp_C = mean(na.omit(temp_c)))%>%
#   ungroup() %>%
# mutate(date_time = paste(year,month,01,sep = "-"))%>%
#   mutate(date_time = strptime(date_time,format = "%Y-%m-%d"))%>%
#   mutate(date_time = lubridate::floor_date(date_time)-1)%>%
#   dplyr::filter(!is.na(date_time))%>%
#   dplyr::select(date_time,station_name, monthly_temp_C) %>%
#   pivot_wider(values_from = monthly_temp_C,
#               names_from = station_name,
#               values_fn = mean)%>%
#     xts::xts(order.by = .$date_time) -> focal_mean_temp
#   
#     
#       dygraph(data = focal_mean_temp[,colnames(focal_mean_temp)[which(colnames(focal_mean_temp)!="date_time")]],
#           main = "Temperature",
#           xlab = "Date",
#           ylab = "Temp. (C)") %>%
#     dySeries()%>%
#     dyRangeSelector(dateWindow = c( Sys.Date() - time_window_days, Sys.Date())) -> temp_graph
# 


```



```{r plot_precip, echo=F, eval = TRUE, message = F, fig.width = 10, fig.height = 6}
#| fig-cap: 
#|   - "Figure 2. Climate Data from GSOD.  Mean data is a long-term average for each day of the year across these weather stations."
  #This code chunk plots the targets visualization.
  # I do this in two steps to avoid errors that otherwise can occur

  precip_graph

```


```{r plot_temp, echo=F, eval = TRUE, message = F, fig.width = 10, fig.height = 6}
#| fig-cap: 
#|   - "Figure 2. Climate Data from GSOD.  Mean data is a long-term average for each day of the year across these weather stations."


  #This code chunk plots the targets visualization.
  # I do this in two steps to avoid errors that otherwise can occur

  #temp_graph
  mean_temp_graph

```

## Drought Indices

### NDWI
```{r NDWI_plot, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE}

library(raster)
library(mapview)
library(leaflet)
library(leafem)


  
  leaflet(data = focal_wgs) %>%
  addProviderTiles("Esri.NatGeoWorldMap", group = "NatGeo") %>%
    #addProviderTiles("NASAGIBS.ModisTerraTrueColorCR", group = "True Colors") %>%
    addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") %>%
  addPolygons(color = "black",
              stroke = TRUE,
              fill = FALSE,
              group = "Park") %>%
  addRasterImage(x = ndwi_rast,
                 group = "NDWI",
                 #colors = ndwi_pal
                 colors = ndwi_bin_pal,
                 opacity = 0.8
                 )%>% 
  addMouseCoordinates() %>%
      addImageQuery(ndwi_rast, type="mousemove", layerId = "NDWI") %>%
  leaflet::addLegend(position = "bottomright",
            #pal = ndwi_pal,
            pal = ndwi_bin_pal,
            values = ~values(ndwi_rast),
            opacity = 1,
            title = "NDWI") %>%
    addLayersControl(
    baseGroups = c("NatGeo","World Imagery"),
    overlayGroups = c("NDWI", "Park"),
    options = layersControlOptions(collapsed = FALSE),position = "topright") %>%
  fitBounds(bbox[1], bbox[2], bbox[3], bbox[4])


```

The Normalized Difference Water Index [(NDWI)](https://en.wikipedia.org/wiki/Normalized_difference_water_index) is a measure of the water content of leaves ranging between -1 (no water) and 1 (water). The NDWI data were last updated on `r most_recent_ndwi_date` (although they may be older than the update date).

Interpreting NDWI:

  * 1 - 0.2 = Water surface,
  * 0.2 – 0.0 = Flooding, humidity,
  * 0.0 – -0.3 = Moderate drought, non-aqueous surfaces,
  * -0.3 – -1 = Drought, non-aqueous surface
  
### SPI


The Standardized Precipitation Index [(SPI)](https://gmao.gsfc.nasa.gov/research/subseasonal/atlas/SPI-html/SPI-description.html#:~:text=The%20SPI%20is%20used%20for,from%20subseasonal%20to%20interannual%20scales.) is a drought index ranging from -3 (very dry) to +3 (very wet).



```{r calc_spi, eval = TRUE, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE}

library(SPEI)
require(ggplot2)


  #Make a dataset with only mostly complete data

  stations_to_keep <-
  focal_precip %>%
    as.data.frame()%>%
    pivot_longer(cols = !date_time,
                 names_to = "station_name",
                 values_to = "monthly_precip_mm") %>%
    group_by(station_name) %>%
    summarize(fraction_na = sum(is.na(monthly_precip_mm))/length(monthly_precip_mm)) %>%
    filter(fraction_na < 0.05) %>%
    dplyr::select(station_name)

  
  focal_precip %>%
    as.data.frame() %>%
    .[stations_to_keep$station_name] %>%
     mutate_if(is.character, as.numeric)-> focal_spi_data

  focal_spi_data %>%
    dplyr::select(!mean) -> focal_spi_data
  
    #calculate spi at different temporal windows

    spi_1 <- spi(data = ts(focal_spi_data,
                           frequency = 12,
                           start = c(rownames(focal_spi_data)[1]%>%
                                       substr(start = 0,stop = 4),
                                     rownames(focal_spi_data)[1]%>%
                                       substr(start = 6,stop = 7))),
                 scale =  1,
                 verbose = FALSE,
                 na.rm = TRUE)
    
    
    spi_3 <- spi(data = ts(focal_spi_data,
                           frequency = 12,
                           start = c(rownames(focal_spi_data)[1]%>%
                                       substr(start = 0,stop = 4),
                                     rownames(focal_spi_data)[1]%>%
                                       substr(start = 6,stop = 7))),
                 scale =  3,
                 verbose = FALSE,
                 na.rm = TRUE)
    
    spi_12 <- spi(data = ts(focal_spi_data,
                           frequency = 12,
                           start = c(rownames(focal_spi_data)[1]%>%
                                       substr(start = 0,stop = 4),
                                     rownames(focal_spi_data)[1]%>%
                                       substr(start = 6,stop = 7))),
                 scale =  12,
                 verbose = FALSE,
                 na.rm = TRUE)

plot(spi_1)+
  ggtitle('1 Month SPI')

plot(spi_3)+
  ggtitle('3 Month SPI')

plot(spi_12)+
  ggtitle('12 Month SPI')



```
