---
title: "Park Report"
params:
  focal_park_name: "Dyer Island Nature Reserve Complex"
---


```{r, echo=F, message = F, results = "hide"}
library(targets)
library(tidyverse)
library(doParallel)
#library(raster)
library(lubridate)
library(sf)
library(xts)
library(plotly)
library(leaflet)
library(dygraphs)
library(terra)
library(cowplot)
library(ggridges)  
library(dygraphs)
library(mapview)
library(leafem)
library(SPEI)

```

```{r load_targets, echo=F, message=FALSE}
tar_load(protected_areas)
#tar_load(most_recent_fire.tif)
tar_load(park_fire_history)
tar_load(temp_directory)
tar_load(years_since_fire.tif)
tar_load(fires_wgs)
tar_load(most_recent_ndvi.tif)
tar_load(most_recent_ndvi_date)
tar_load(monthly_mean_ndvi.tif)
tar_load(monthly_delta_ndvi.tif)
tar_load(weather_data)
#tar_load(mean_ndvi.tif)
#tar_load(delta_ndvi.tif)
#tar_load(most_recent_quarter_ndvi_file)
#tar_load(quarterly_delta_ndvi.tif)
tar_load(stations)
tar_load(inat_data)


time_window_days=365

```


```{r data_prep, echo = FALSE, warning = FALSE, message = FALSE,include=FALSE}

# get focal park from yaml
focal_park_name <- params$focal_park_name

# set for testing
if(F) focal_park_name <- "Table Mountain National Park"


focal_park=protected_areas |> 
  st_as_sf() |> 
  filter(name==focal_park_name)


# CREATE wgs84 version of the park polygon

    focal_park |> 
    st_transform(crs = st_crs(4326)) |> 
    st_make_valid() -> 
    focal_wgs

# Create buffered fire age polygon

    # make park-specific fire ages file
      

      fires_wgs %>%
      st_crop(y = focal_wgs %>%
                st_buffer(dist = 10000)) ->
        focal_fires
      
      park_no_spaces <- gsub(pattern = " ",replacement = "_",x = focal_park_name)

      # focal_fires %>%
      #   st_write(dsn = file.path(temp_directory, paste(park_no_spaces,"fires.gpkg",sep = "_")),
      #            append=FALSE,
      #            quiet = TRUE
      #            )
      # 
      # robust_pb_upload(file = file.path(temp_directory, paste(park_no_spaces,"fires.gpkg",sep = "_")),
      #                  repo = "AdamWilsonLab/emma_report",
      #                  tag = park_data_tag)
      # 
      # file.remove(file.path(temp_directory, paste(park_no_spaces,"fires.gpkg",sep = "_")))
      

# Park-specific file link
#    park_fires_file  <- paste("https://github.com/AdamWilsonLab/emma_report/releases/download/park_data/",
#                              paste(park_no_spaces,"fires.gpkg",sep= "_"),sep = "")

# Create a truncated version of the fire maps (ranging from 1-20)

  fires_wgs %>%
    mutate(Years = case_when(Years > 20 ~ 20,
                             Years <=20 ~ Years)) -> fires_wgs_truncated
  


#Note that the "addLegend_decreasing" isn't quite right, but might be close enough if you feel strongly about the ordering

addLegend_decreasing <- function (map, position = c("topright", "bottomright", "bottomleft", 
			    "topleft"), pal, values, na.label = "NA", bins = 7, colors, 
		  opacity = 0.5, labels = NULL, labFormat = labelFormat(), 
		  title = NULL, className = "info legend", layerId = NULL, 
		  group = NULL, data = getMapData(map), decreasing = FALSE) {
	position <- match.arg(position)
	type <- "unknown"
	na.color <- NULL
	extra <- NULL
	if (!missing(pal)) {
		if (!missing(colors)) 
			stop("You must provide either 'pal' or 'colors' (not both)")
		if (missing(title) && inherits(values, "formula")) 
			title <- deparse(values[[2]])
		values <- evalFormula(values, data)
		type <- attr(pal, "colorType", exact = TRUE)
		args <- attr(pal, "colorArgs", exact = TRUE)
		na.color <- args$na.color
		if (!is.null(na.color) && col2rgb(na.color, alpha = TRUE)[[4]] == 
		    0) {
			na.color <- NULL
		}
		if (type != "numeric" && !missing(bins)) 
			warning("'bins' is ignored because the palette type is not numeric")
		if (type == "numeric") {
			cuts <- if (length(bins) == 1) 
				pretty(values, bins)
			else bins	
			
			if (length(bins) > 2) 
				if (!all(abs(diff(bins, differences = 2)) <= 
				         sqrt(.Machine$double.eps))) 
					stop("The vector of breaks 'bins' must be equally spaced")
			n <- length(cuts)
			r <- range(values, na.rm = TRUE)
			cuts <- cuts[cuts >= r[1] & cuts <= r[2]]
			n <- length(cuts)
			p <- (cuts - r[1])/(r[2] - r[1])
			extra <- list(p_1 = p[1], p_n = p[n])
			p <- c("", paste0(100 * p, "%"), "")
			if (decreasing == TRUE){
				colors <- pal(rev(c(r[1], cuts, r[2])))
				labels <- rev(labFormat(type = "numeric", cuts))
			}else{
				colors <- pal(c(r[1], cuts, r[2]))
				labels <- rev(labFormat(type = "numeric", cuts))
			}
			colors <- paste(colors, p, sep = " ", collapse = ", ")
			
		}
		else if (type == "bin") {
			cuts <- args$bins
			n <- length(cuts)
			mids <- (cuts[-1] + cuts[-n])/2
			if (decreasing == TRUE){
				colors <- pal(rev(mids))
				labels <- rev(labFormat(type = "bin", cuts))
			}else{
				colors <- pal(mids)
				labels <- labFormat(type = "bin", cuts)
			}
			
		}
		else if (type == "quantile") {
			p <- args$probs
			n <- length(p)
			cuts <- quantile(values, probs = p, na.rm = TRUE)
			mids <- quantile(values, probs = (p[-1] + p[-n])/2, 
				 na.rm = TRUE)
			if (decreasing == TRUE){
				colors <- pal(rev(mids))
				labels <- rev(labFormat(type = "quantile", cuts, p))
			}else{
				colors <- pal(mids)
				labels <- labFormat(type = "quantile", cuts, p)
			}
		}
		else if (type == "factor") {
			v <- sort(unique(na.omit(values)))
			colors <- pal(v)
			labels <- labFormat(type = "factor", v)
			if (decreasing == TRUE){
				colors <- pal(rev(v))
				labels <- rev(labFormat(type = "factor", v))
			}else{
				colors <- pal(v)
				labels <- labFormat(type = "factor", v)
			}
		}
		else stop("Palette function not supported")
		if (!any(is.na(values))) 
			na.color <- NULL
	}
	else {
		if (length(colors) != length(labels)) 
			stop("'colors' and 'labels' must be of the same length")
	}
	legend <- list(colors = I(unname(colors)), labels = I(unname(labels)), 
	               na_color = na.color, na_label = na.label, opacity = opacity, 
	               position = position, type = type, title = title, extra = extra, 
	               layerId = layerId, className = className, group = group)
	invokeMethod(map, data, "addLegend", legend)
}


# Create continuous palettes

  pal <- colorNumeric(palette = "Reds",
                      domain = fires_wgs_truncated$Years,
                      reverse = TRUE)

  antipal <- colorNumeric(palette = "Reds",
                          domain = fires_wgs_truncated$Years,reverse = FALSE)
  
  
  ndvi_pal <- colorNumeric(palette = c( "#FFFFCC", "#41B6C4","#0C2C84"),
                           #domain =  values(most_recent_ndvi.tif),
                           domain =  c(-1,0,1),
                           na.color = "transparent")
  
  #max_delta_ndvi <- max(abs(values(delta_ndvi.tif)),na.rm = TRUE)
  max_delta_ndvi <- max(abs(values(monthly_delta_ndvi.tif)),na.rm = TRUE)
  
  delta_ndvi_pal <- colorNumeric(palette = c( "brown", "white","forestgreen"),
                                 #domain =  values(most_recent_ndvi.tif),
                                 domain =  c(max_delta_ndvi*-1,max_delta_ndvi),
                                 na.color = "transparent")

  ndwi_pal <- colorNumeric(palette = c( "#FFFFCC", "#41B6C4","#0C2C84"),
                           #domain =  values(terra::rast(ndwi_rast)),
                           domain = c(-1,1),
                           na.color = "transparent")
  
  ndwi_bin_pal <- colorBin(palette = c( "#FFFFCC", "#41B6C4","#0C2C84"),
                           #domain =  values(terra::rast(ndwi_rast)),
                           domain = c(-1,1),
                           bins = c(-1,-.3,0.0,0.2,1),
                           na.color = "transparent",
                           alpha = TRUE)


# Create bounding box for plotting  
  
bbox <- st_bbox(focal_wgs) %>%
  as.vector()

```

```{r identify_closest_stations, echo = FALSE, warning = FALSE, message = FALSE}

# Process the station and weather data
n_stations=3 # number of stations to show
  # Get data for closest weather stations
  
    cent <- suppressWarnings( focal_park %>%
                                st_union()%>%
                                st_centroid())
    
    closest_stations <- 
      data.frame(station = stations$STNID,
                 name = stations$NAME,
               distance = as.numeric(st_distance(cent,stations)))
    
    closest_stations <- closest_stations[order(closest_stations$distance),]
    
    closest_stations <- closest_stations$station[1:n_stations]
    
    # closest_stations %>%
    #       gsub(pattern = "/",replacement = "",fixed = TRUE)%>% #what kind of sadist puts a slash in a name?
    #       gsub(pattern = " ",replacement = "_") %>%
    #       gsub(pattern = ")",replacement = "_",fixed = TRUE) %>%
    #       gsub(pattern = "(",replacement = "_",fixed = TRUE) %>%
    #       paste(.,".gz.parquet",sep = "")-> closest_stations
    # 

    # robust_pb_download(file = closest_stations,
    #             dest = temp_directory,
    #             repo = "AdamWilsonLab/emma_report",
    #             tag = "GSOD",
    #             max_attempts = max_attempts,
    #             sleep_time = sleep_time,
    #             show_progress=FALSE) -> to_rm
    # 
    # if(exists("to_rm")){rm(to_rm)}
    
  #Hack in case some of the files aren't downloaded correctly.  
    # closest_stations  <- intersect(closest_stations,
    #                                list.files(temp_directory))

    focal_weather=weather_data |> 
      filter(STNID%in%closest_stations)

  if(nrow(focal_weather) < 1){stop("No weather data loaded")}
  
```

```{r reformat_to_match_noaa, echo = FALSE, warning = FALSE, message = FALSE}

  #fix station names in focal weather (missing in many case)
  
    # stations %>%
    # dplyr::select(usaf,wban,station_name)%>%
    # inner_join(y = focal_weather,
    #            by = c("usaf"="usaf_station","wban"="wban_station"),
    #            multiple = "all")%>%
    # dplyr::rename(station_name = station_name.x)-> focal_weather

  #with dygraphs, first element should be x axis, or else do it as an xts
  
  # probably easiest to do xts, since its a time series anyway
  
  # focal_weather %>%
  #   as.data.frame() %>% #for some reason, this code throws an error without this line.  no idea why.
  #   mutate(year = substr(x = date,1,4),
  #          month = substr(x = date,5,6),
  #          day = substr(x=date,7,8),
  #          hour= substr(x=time,1,2),
  #          minute = substr(x=time,3,4)) %>%
  #   mutate(date_time = paste(year,month,day,hour,minute,sep = "-"))%>%
  #   mutate(date_time = strptime(date_time,format = "%Y-%m-%d-%H-%M"))%>%
  #   dplyr::filter(!is.na(date_time)) -> focal_weather
  
  
  #reformatting the GSOD to match NOAA format

  focal_weather %>%
    as.data.frame() %>%
    dplyr::mutate(year = YEAR,
                  month = MONTH,
                  day = DAY,
                  station_name = NAME,
                  mean_precip_mm = PRCP,
                  temp_c = TEMP) %>%
    dplyr::mutate(date_time = paste(year,month,day,sep = "-")) %>%
    dplyr::mutate(date_time = strptime(date_time,format = "%Y-%m-%d")) %>%
    dplyr::filter(!is.na(date_time)) -> focal_weather

```

```{r filter_old_weather_data, echo = FALSE, warning = FALSE, message = FALSE}
  
  #Filter out oldest data
  min_date = "1970-01-01"
  focal_weather <- 
    focal_weather %>%
    dplyr::filter(date_time > as_datetime(min_date,tz =tz(focal_weather$date_time)))

```

```{r generate_precip_dataset, echo = FALSE, warning = FALSE, message = FALSE}
  
  #Generate precip dataset
  
# focal_weather %>%
#   group_by(station_name,year,month)%>%
#   summarise(monthly_precip_mm = sum(na.omit(mean_precip_mm)))%>%
#   ungroup() %>%
#   mutate(date_time = paste(year,month,01,sep = "-"))%>%
#   mutate(date_time = strptime(date_time,format = "%Y-%m-%d"))%>%
#   mutate(date_time = lubridate::floor_date(date_time)-1)%>%
#   dplyr::filter(!is.na(date_time))%>%
#   dplyr::select(date_time,station_name, monthly_precip_mm) %>%
#    filter(date_time>as_date("2000-01-01")) |> 
#   pivot_wider(values_from = monthly_precip_mm,
#               names_from = station_name,
#               values_fn = mean) %>%
#    mutate(doy =  lubridate::yday(date_time) ) %>%
#    left_join(x=.,
#              y  = group_by(., doy) %>%
#                summarize(mean = mean(c_across(!contains(c("doy","date_time"))),
#                                          na.rm=TRUE))
#              ) %>%
#  dplyr::select(-doy)%>%
#   xts::xts(order.by = .$date_time) -> focal_precip
  

library(zoo)
# Set the rolling window size (must be odd for centering)
window_size <- 61  # e.g., ±15 days = 31 total

# Step 1: Prepare the daily data
focal_precip <- focal_weather %>%
  filter(!is.na(mean_precip_mm)) %>%
  select(station_name,date_time,mean_precip_mm) %>%
  mutate(date_time = as_date(date_time)) %>%
#  filter(date_time > as_date("2000-01-01")) %>%
  pivot_wider(
    names_from = station_name,
    values_from = mean_precip_mm,
    values_fn = mean
  ) %>%
  mutate(doy = yday(date_time))

# Step 2: Compute the daily climatology using all years
# Average across stations by DOY
focal_precip_climatology <- focal_precip %>%
  group_by(doy) %>%
  summarise(clim_mean = mean(c_across(where(is.numeric)), na.rm = TRUE), .groups = "drop") %>%
  arrange(doy)

# Step 3: Apply rolling mean (wrap around to handle year start/end)
# Pad the data for wrap-around
extended <- bind_rows(
  focal_precip_climatology %>% filter(doy > (366 - window_size)),
  focal_precip_climatology,
  focal_precip_climatology %>% filter(doy <= window_size)
)

# Compute the rolling mean twice to smooth it out
extended$roll_mean <- zoo::rollmean(extended$clim_mean, k = window_size, fill = NA, align = "center") |> 
  zoo::rollmean(k = window_size, fill = NA, align = "center")

# Step 4: Remove padding and match back to original DOY
rolling_climatology <- extended %>%
  slice((window_size + 1):(n() - window_size)) %>%
  select(doy, mean = roll_mean)

# Step 5: Join back to the daily weather data
focal_precip %>%
  left_join(rolling_climatology, by = "doy") %>%
  select(-doy) %>%
   xts::xts(x=select(.,-date_time), order.by = .$date_time) -> focal_precip


# calculate monthly totals
  bind_cols(date_time=time(focal_precip),as.data.frame(focal_precip)) |> 
    mutate(year=year(as_date(date_time)),month=month(as_date(date_time))) |> 
    pivot_longer(-c(date_time,month,year),names_to="station",values_to="precip") |> 
    group_by(station,year,month) |> 
      summarize(precip=sum(precip,na.omit=T)) |> 
      arrange(station,year,month) |> 
    ungroup() |> 
    mutate(date_time=ymd(paste(year,month,15))) |> 
    select(-year,-month) |> 
    pivot_wider(id_cols="date_time",names_from=station,values_from=precip)-> 
    focal_precip_monthly
  
  focal_precip_monthly_xts <- xts::xts(x=select(focal_precip_monthly,-date_time), order.by = focal_precip_monthly$date_time) 


```

```{r generate_temp_dataset, echo = FALSE, warning = FALSE, message = FALSE}

    #mean daily temp dataset

  focal_weather%>%
  group_by(station_name,year,month,day)%>%
  summarise(daily_temp_C = mean(na.omit(temp_c)))%>%
  ungroup() %>%
mutate(date_time = paste(year,month,day,sep = "-"))%>%
  mutate(date_time = strptime(date_time,format = "%Y-%m-%d"))%>%
  dplyr::filter(!is.na(date_time))%>%
  dplyr::select(date_time,station_name, daily_temp_C) %>%
  pivot_wider(values_from = daily_temp_C,
              names_from = station_name,
              values_fn = mean) %>%
   mutate(doy =  lubridate::yday(date_time) ) %>%
   left_join(x=.,
             y  = group_by(., doy) %>%
               summarize(mean = mean(c_across(!contains(c("doy","date_time"))),
                                         na.rm=TRUE))
             ) %>%
  dplyr::select(-doy)%>%
    xts::xts(order.by = .$date_time) -> focal_mean_daily_temp

```

```{r generate_sf_of_stations, echo = FALSE, warning = FALSE, message = FALSE}
  
  
#Generate sf of station points
  
  # focal_stations_sf <-
  # stations_sf %>%
  #   filter(usaf %in%gsub(pattern = ".gz.parquet",
  #                        replacement = "",x = closest_stations)) %>%
  #   st_transform(st_crs(fires_wgs_truncated))

  focal_stations_sf <-
  stations %>%
    filter(STNID %in% gsub(pattern = ".gz.parquet",
                          replacement = "",
                          x = closest_stations)) %>%
    st_transform(st_crs(fires_wgs_truncated))
    
```

```{r crop invasives, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE}

inat_data %>%
  filter(invasive==T & 
           as_date(observed_on)>(today()-as.difftime(900, units = "days"))) |> 
      st_crop(y = focal_wgs %>%
                st_buffer(dist = 1000)) -> focal_invasives


inat_data %>%
  filter(invasive==T & 
           as_date(observed_on)<=(today()-as.difftime(900, units = "days"))) |> 
      st_crop(y = focal_wgs %>%
                st_buffer(dist = 1000)) -> focal_old_invasives


# if there are no data, make a dataframe with NAs so that leaflet doesn't fail (will still throw error)

if(nrow(focal_invasives) == 0){
  

  invasive_labels <- NULL
  
}else{
  
  invasive_labels <- focal_invasives$scientific_name
  
}

```


# `r focal_park_name`


## NDVI and Time Since Fire


```{r ndvi_and_burns, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE}

  leaflet(data = focal_wgs) %>%
  addProviderTiles("Esri.NatGeoWorldMap", group = "NatGeo") %>%
    #addProviderTiles("NASAGIBS.ModisTerraTrueColorCR", group = "True Colors") %>%
    addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") %>%
  addPolygons(color = "black",
              stroke = TRUE,
              fill = FALSE,
              group = "Park") %>%
  addRasterImage(x = raster::raster(most_recent_ndvi.tif),
                 group = "NDVI",
                 colors = ndvi_pal) %>%
    # addRasterImage(x = raster::raster(delta_ndvi.tif),
    #              group = "delta NDVI<br/>(long-term)",
    #              colors = delta_ndvi_pal) %>%
  # addRasterImage(x = raster::raster(quarterly_delta_ndvi.tif),
  #              group = "delta NDVI<br/>(quarterly)",
  #              colors = delta_ndvi_pal) %>%
  addRasterImage(x = raster::raster(monthly_delta_ndvi.tif),
                 group = "delta NDVI<br/>(monthly)",
                 colors = delta_ndvi_pal) %>%
  hideGroup("delta NDVI<br/>(quarterly)") %>%
  
  # Add recent invasive species
   
  addCircleMarkers(data = focal_invasives,
             label = invasive_labels,
             group = "Invasives (new)",
             stroke = FALSE,
             fillOpacity = 1,
             fillColor = "darkgrey",
             radius = 5) %>%
  
  addPolygons(data = fires_wgs_truncated,
              color = "red",
              fill = TRUE,
              fillOpacity = 0,
              stroke = TRUE,
              label = paste(fires_wgs$Years, "years since burn"),
              weight = 1,
              group = "Fire Outlines") %>%
    addPolygons(data = fires_wgs_truncated,
              color = ~antipal(Years),
              fillOpacity = .75,
              stroke = FALSE,
              label = fires_wgs$Years,
              group = "Fires") %>%
    addMarkers(data = focal_stations_sf,
               label = focal_stations_sf$station_name,
               group = "Stations") %>%
    
    # turn off some layers by default
  
    hideGroup("Stations") %>%
    hideGroup("Invasives (new)") %>%
    hideGroup("NDVI") %>%
    hideGroup("delta NDVI<br/>(long-term)") %>%
  
    # add legends
  
    leaflet::addLegend(position = "topright",
                     pal = delta_ndvi_pal,          
                     values = ~values(monthly_delta_ndvi.tif),
                     #values = ~c(-1,1),
                     opacity = 1,
                     title = "delta<br/>NDVI") %>%
  
    leaflet::addLegend(position = "topright",
            pal = ndvi_pal,          
            values = ~values(raster::raster(most_recent_ndvi.tif)),
            #values = ~c(-1,1),
            opacity = 1,
            title = "NDVI") %>%

    addLegend_decreasing(position = "bottomright",
            pal = pal,
            values = ~fires_wgs_truncated$Years,
    title = "Years<br/>Since<br/>Fire",
    opacity = 1) %>%
  
    addLayersControl(
    baseGroups = c("NatGeo","World Imagery"),
    overlayGroups = c("Park",
                      "Stations",
                      "delta NDVI<br/>(monthly)",
                      "delta NDVI<br/>(long-term)",
                      #"delta NDVI<br/>(quarterly)",
                      "NDVI",
                      "Fire Outlines",
                      "Fires",
                      "Invasives (new)"
                      ),
    options = layersControlOptions(collapsed = FALSE),position = "topleft") %>%
  fitBounds(bbox[1], bbox[2], bbox[3], bbox[4])

```

Figure 1. Leaflet map showing delta NDVI, NDVI, number of years since the most recent fire, and recent invasive species records. NA values in the delta NDVI and NDVI layers indicate missing data (e.g. due to clouds, water, etc.). Delta NDVI is the difference between observed NDVI and expected NDVI (i.e., the long-term mean). Monthly delta NDVI is calculated relative to the mean NDVI of the current month across the MODIS record while long-term delta NDVI is calculated relative the mean NDVI across the entire MODIS record. NA values in the delta NDVI layer indicate missing data (e.g. due to clouds, water, etc.). NDVI data are from `r most_recent_ndvi_date`. NA values in the fire layer indicate that no fires have been recorded for that area. Note that the color scale for fires has been truncated, and any sites with more than 20 years since fire appear as 20. The number of years since fire can be seen by hovering your cursor over the polygon of interest. Vegetation age polygons for the park are available at: `#r park_fires_file`. A raster layer of vegetation age (years since fire) is available at https://github.com/AdamWilsonLab/emma_report/releases/download/current/years_since_fire.tif .The mean current NDVI layer is available at https://github.com/AdamWilsonLab/emma_envdata/releases/download/current/mean_ndvi.tif .

## Area burned and vegetation ages

```{r vegetation ages over time, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE}

# Subset park_fire_history to only the focal park

  # use the ndvi raster as a template to get cells in park

    most_recent_ndvi.tif %>%
      terra::extract(y = vect(focal_park),
                     cells = TRUE,
                     touches = TRUE) %>%
    dplyr::select(cell) -> focal_cells

  # subset fire data

  focal_fires <-
    park_fire_history %>%
    filter(cellID %in% focal_cells$cell)
  
  
  # if empty, fill in NAs
  
    if(nrow(focal_fires) == 0){
      
      focal_fires <- expand.grid(cellID = focal_cells$cell,
                                 date = unique(park_fire_history$date),
                                 days_since_fire = NA)  
      
      
    }
  
    
  # dealing with missing cells/ages
  
    focal_fires %>%
      pivot_wider(names_from = date,
                  values_from = days_since_fire) %>%
      full_join(y = focal_cells,
                by = c("cellID"="cell")) %>%
      pivot_longer(cols = !1, # make sure this ncol is pointing to the correct thing
                   names_to = "date",
                   values_to = "days_since_fire") %>%
                mutate(cellID = as.factor(cellID),
                       years_since_fire = days_since_fire/365.25,
                       date =as.numeric(date))%>%
                    mutate(date = as_date(date),
                       year = year(date))%>%
      mutate(years_since_fire = case_when(is.na(years_since_fire) ~ 20,
                                          years_since_fire >= 0 ~ years_since_fire,
                                          years_since_fire < 0 ~ 20)) -> ff2
  
        
ff2 %>%
  mutate(gte20 = years_since_fire >= 20) %>%
  group_by(year,gte20) %>%
  count()%>%
  ungroup()%>%
  group_by(year)%>%
  mutate(total=sum(n))%>%
  mutate(fraction = n/total)%>%
  filter(gte20)-> unburned_summary        
        
ff2 %>%
  filter(years_since_fire<20)%>%
  mutate(year=as.factor(year))%>%
ggplot(mapping = aes(x=years_since_fire,
                     y=year,
                     fill=after_stat(x)))+
  geom_density_ridges_gradient()+
  labs(fill = "Age")+
  xlab("Vegetation Age Distribution")+
  ylab("Year")+
  theme_bw()+
  theme(legend.position = "none")+
  geom_text(data = unburned_summary,
            aes(label = paste(round(fraction,2)*100,"%"),
                y=as.factor(year),
                x = max(ff2$years_since_fire)), 
            position = position_stack(),
            inherit.aes = F)+
  scale_y_discrete(expand = c(.05, 0.2))+
  coord_flip() -> p1
        

focal_fires |> 
  mutate(year=year(as_date(date))) |> 
  group_by(year) |> 
  summarize(area_burned=sum(ifelse(days_since_fire<45,1,0))) |>
  ggplot(aes(x=year,y=area_burned))+
  geom_line()+
  ylab("Area Burned")+
  xlab("")+
   scale_x_continuous(
      breaks = seq(min(year(as_date(focal_fires$date))), max(year(as_date(focal_fires$date))), by = 1)) ->  # One tick per year
  p_burnedarea

plot_grid(p_burnedarea, p1, ncol=1, align = "v", labels = "AUTO",rel_heights = c(0.3,0.7),label_size = 0) 
     
```

Figure 2. Top: Total area burned each year in the park.  Bottom: Ridgeplot histogram showing vegetation age distributions within the park over time. Percentages shown represent amount of vegetation that is 20 years old or older. Note that areas where fires are not known to have occurred have been assigned a vegetation age of 20 years.


```{r vegetation ages, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE, eval=F}
  
## Current Vegetation Age Distribution

  # set NA values to 21 (we'll reset anything higher than 20 to 20+ for visualization)
  # mask years since fire raster to the park

  ysf_masked <- years_since_fire.tif
  ysf_masked[is.na(ysf_masked)] <- 21
  ysf_masked %>%
  mask(focal_park) -> ysf_masked

  # library(tidyterra)
  # ggplot()+
  #   geom_sf(data = focal_park)+
  #   geom_spatraster(data = ysf_masked %>%
  #                     crop(ext(focal_park)),
  #                   mapping = aes(fill = lyr.1))+
  #   coord_sf(crs=crs(ysf_masked))+
  #   scale_fill_terrain_c()
  
  data.frame(Vegetation_Age = values(ysf_masked) %>%
               as.vector()) %>%
    filter(!is.na(Vegetation_Age)) %>%
    mutate( Vegetation_Age = case_when(Vegetation_Age > 20 ~ 20,
                                       .default = Vegetation_Age)) %>%
    mutate(Vegetation_Age = round(x = Vegetation_Age, digits = 2))-> test
  
  
    km2_per_pixel <- res(ysf_masked)[1]*res(ysf_masked)[2]*1e-6
    
    
    
    test %>%
    ggplot(mapping = aes(x = Vegetation_Age))+
    geom_histogram()+
    xlab("Vegetation Age (years)")+
    scale_x_continuous(breaks = c(0,5,10,15,20),
    labels = c(0,5,10,15,"20(+)"),
    limits = c(0,21),
    expand = c(0,0))+
      #convert to km2
    scale_y_continuous(expand = c(0,0),
                       labels = function(x){
                         round(x * res(ysf_masked)[1] * res(ysf_masked)[2] * 1e-6,
                                                  digits = 0)})+
      ylab(expression(paste("Area ", (km^2) )))+
    theme_bw()
    

    
Figure 3. Histogram of vegetation ages. For the purposes of this plot, any vegetation known to either be 20 years old or older, or for which we have no recorded records of fire, has been assigned an age of 20(+) years. The area shown was calculated by mutliplying counts of MODIS pixels at each age with the area of each pixel in square kilometers.



```


## Weather Data

```{r weatherdyplot, echo=FALSE, message=FALSE, warning=FALSE}

  # see: https://rstudio.github.io/dygraphs/

# Define a shared group name
shared_group <- "weather_group"

focal_precip_df <- as.data.frame(focal_precip) |> 
   mutate(across(where(is.numeric) & !any_of("date_time"), function(x) log1p(ifelse(x<0.001,0,x))))

focal_precip_trans <- ts(focal_precip_df,
                         start = start(focal_precip),
                         frequency = frequency(focal_precip))

dygraph(focal_precip_trans,
        main = "Precipitation (log1p-transformed)",
        xlab = "Date",
        ylab = "log1p(Precip mm)",
       group = shared_group) %>%
      dyAxis("y",
         label = "Precip. (mm)",
         axisLabelFormatter = JS(
           "function(value, granularity, opts, dygraph) {
              return Math.round(Math.exp(value) - 1);
            }"
         ),
         valueFormatter = JS(
    "function(num, opts, seriesName, g, row, col) {
       return (Math.exp(num) - 1).toFixed(2);
     }"
  ))  |> 
  dySeries() %>%
  dyRangeSelector() ->
  precip_graph


      dygraph(data = focal_mean_daily_temp[,colnames(focal_mean_daily_temp)[which(colnames(focal_mean_daily_temp)!="date_time")]],
          main = "Temperature",
          xlab = "Date",
          ylab = "Temp. (C)",
          group = shared_group) %>%
    dySeries() %>%
    dyRangeSelector(dateWindow = c( Sys.Date() - time_window_days, Sys.Date())) -> mean_temp_graph

```

```{r plot_precip, echo=F, eval = TRUE, message = F, fig.width = 10, fig.height = 6}
#| fig-cap: 
#|   - "Figure 4. Climate Data from GSOD.  Mean data is a long-term average for each day of the year across these weather stations."
  #This code chunk plots the targets visualization.
  # I do this in two steps to avoid errors that otherwise can occur

  precip_graph

```

```{r plot_temp, echo=F, eval = TRUE, message = F, fig.width = 10, fig.height = 6}
#| fig-cap: 
#|   - "Figure 5. Climate Data from GSOD.  Mean data is a long-term average for each day of the year across these weather stations."


  #This code chunk plots the targets visualization.
  # I do this in two steps to avoid errors that otherwise can occur

  #temp_graph
  mean_temp_graph

```

## Drought Indices

```{r NDWI_plot, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE, eval=FALSE, include=FALSE}
  leaflet(data = focal_wgs) %>%
  addProviderTiles("Esri.NatGeoWorldMap", group = "NatGeo") %>%
    #addProviderTiles("NASAGIBS.ModisTerraTrueColorCR", group = "True Colors") %>%
    addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") %>%
  addPolygons(color = "black",
              stroke = TRUE,
              fill = FALSE,
              group = "Park") %>%
  addRasterImage(x = ndwi_rast,
                 group = "NDWI",
                 #colors = ndwi_pal
                 colors = ndwi_bin_pal,
                 opacity = 0.8
                 )%>% 
  addMouseCoordinates() %>%
      addImageQuery(ndwi_rast, type="mousemove", layerId = "NDWI") %>%
  leaflet::addLegend(position = "bottomright",
            #pal = ndwi_pal,
            pal = ndwi_bin_pal,
            values = ~values(ndwi_rast),
            opacity = 1,
            title = "NDWI") %>%
    addLayersControl(
    baseGroups = c("NatGeo","World Imagery"),
    overlayGroups = c("NDWI", "Park"),
    options = layersControlOptions(collapsed = FALSE),position = "topright") %>%
  fitBounds(bbox[1], bbox[2], bbox[3], bbox[4])

# Below is the text that accompanies this figure  
#   Figure 6. The Normalized Difference Water Index [(NDWI)](https://en.wikipedia.org/wiki/Normalized_difference_water_index) is a measure of the water content of leaves ranging between -1 (no water) and 1 (water). The NDWI data were last updated on `r most_recent_ndwi_date` (although they may be older than the update date).
# 
# Interpreting NDWI:
# 
#   * 1 - 0.2 = Water surface,
#   * 0.2 – 0.0 = Flooding, humidity,
#   * 0.0 – -0.3 = Moderate drought, non-aqueous surfaces,
#   * -0.3 – -1 = Drought, non-aqueous surface

  

```

### SPI

The Standardized Precipitation Index [(SPI)](https://gmao.gsfc.nasa.gov/research/subseasonal/atlas/SPI-html/SPI-description.html#:~:text=The%20SPI%20is%20used%20for,from%20subseasonal%20to%20interannual%20scales.) is a drought index ranging from -3 (very dry) to +3 (very wet).

```{r calc_spi_1, eval = TRUE, fig.width = 10, fig.height = 7, echo = FALSE, warning = FALSE, message = FALSE}

  #Make a dataset with only mostly complete data

  stations_to_keep <-
    bind_cols(date_time=time(focal_precip_monthly_xts),focal_precip_monthly_xts)%>%
    pivot_longer(cols = !date_time,
                 names_to = "station_name",
                 values_to = "monthly_precip_mm") %>%
    group_by(station_name) %>% 
    summarize(fraction_na = sum(is.na(monthly_precip_mm))/length(monthly_precip_mm)) %>% 
    filter(fraction_na < 0.05) %>%
    dplyr::select(station_name)

  
  focal_precip_monthly_xts %>%
     as.data.frame() %>%
    .[stations_to_keep$station_name] %>%
     mutate_if(is.character, as.numeric) -> focal_spi_data

  
  # Only use the mean estimates if those are the only complete ones

    #focal_spi_data %>%
    #dplyr::select(!mean) -> focal_spi_data
      
      
    if(ncol(focal_spi_data)>0){
  
      spi_window=6 # number of months of moving window

spi <- spi(data = ts(focal_spi_data,
                           frequency = 12,
                           start = c(rownames(focal_spi_data)[1]%>%
                                       substr(start = 0,stop = 4),
                                     rownames(focal_spi_data)[1]%>%
                                       substr(start = 6,stop = 7))),
                 scale =  spi_window,
                 verbose = FALSE,
                 na.rm = TRUE)

spi2 <- as_tibble(spi$fitted) %>%
  mutate(date = as.Date(as.yearmon(time(spi$fitted)))) %>%
  relocate(date) %>%
  pivot_longer(-date, names_to = "station", values_to = "spei") #|> 
 # mutate(       # Create a new column to separate positive and negative SPEI
#    spei_pos = ifelse(spei > 0, spei, 0),
#    spei_neg = ifelse(spei < 0, spei, 0)
#  )




    }
      
```

```{r spiplot, eval = TRUE, fig.width = 10, fig.height = 10, echo = FALSE, warning = FALSE, message = FALSE}

  if(ncol(focal_spi_data)>0){

# # Plot with separate fill colors for positive and negative values
# ggplot(spi2, aes(x = date)) +
#   geom_hline(yintercept = 0, color = grey(0.6)) +
# #  geom_line(aes(y = spei), col="transparent") + #for plotly to return simple value?
#   geom_area(aes(y = spei_pos), fill = "darkblue") +
#   geom_area(aes(y = spei_neg), fill = "darkred") +
#   geom_smooth(aes(y = spei), span = 0.2, se = TRUE,col="black") +
#   ggtitle("6 Month Standardized Precipitation Index (SPI)") +
#   ylab("Standardized Precipitation Index (SPI)")+
#   xlab("Date") +
#   facet_wrap(~station,ncol=1)+
#       coord_equal(ratio = 100)+
#   theme_minimal()  -> p_spi
#   
#     #ggplotly(p_spi,layerData = 2)
#      p_spi
#   }


# Plot with separate fill colors for positive and negative values
ggplot(spi2, aes(x = date)) +
  geom_hline(yintercept = 0, color = grey(0.6)) +
  geom_line(aes(y = spei,col=station)) + 
  geom_smooth(aes(y = spei), span = 0.3, se = TRUE,col="black") +
  ggtitle(paste0("Standardized Precipitation Index (SPI with ",spi_window," Month window)")) +
  scale_color_viridis_d()+
  ylab("Standardized Precipitation Index (SPI)")+
  xlab("Date") +
  theme_minimal()  -> p_spi

    p_spi
    
    spi2 |> 
      pivot_wider(names_from = station,values_from = spei) |> 
      dygraph(
          main = "Standardized Precipitation Index (SPI with 6 Month window)",
          xlab = "Date",
          ylab = "SPI",
          group = shared_group) %>%
    dySeries() %>%
    dyRangeSelector(dateWindow = c( Sys.Date() - time_window_days, Sys.Date())) -> spi_graph
    
    
  spi_graph
    
}
```

# Report Metadata

This table summarizes the date this report was generated and the most recent observation for each data type.

```{r, echo=F, results='asis'}
# build table of dates when products were last updated

dates <- bind_rows(
  data.frame(Description = "Website", Date = format(now(), "%Y-%b-%d")),
  data.frame(Description = "NDVI", Date = format(most_recent_ndvi_date, "%Y-%b-%d")),
  data.frame(Description = "Weather", Date = format(max(focal_weather$date_time), "%Y-%b-%d"))
) |> 
  select(Description, "Date last updated"=Date)

knitr::kable(dates)
 
```
